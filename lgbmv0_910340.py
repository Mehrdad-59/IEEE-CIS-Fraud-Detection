# -*- coding: utf-8 -*-
"""IEEE-CIS Fraud Detection_lgbmv0.910340.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XAvjBajhfZTG1do93tt2mgVx-x0-o9JI
"""

import pandas as pd
import numpy as np
from sklearn.metrics import roc_auc_score
import random
from lightgbm import LGBMClassifier
from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold
from scipy.stats.mstats import gmean

import gc
import warnings
warnings.filterwarnings('ignore')

def reduce_memory_usage(df):
    start_mem_usg = df.memory_usage().sum() / 1024**2 
    print("Memory usage of properties dataframe is :",start_mem_usg," MB")
    NAlist = [] # Keeps track of columns that have missing values filled in. 
    for col in df.columns:
        if df[col].dtype != object:  # Exclude strings            
            # Print current column type
            print("******************************")
            print("Column: ",col)
            print("dtype before: ",df[col].dtype)            
            # make variables for Int, max and min
            IsInt = False
            mx = df[col].max()
            mn = df[col].min()
            print("min for this col: ",mn)
            print("max for this col: ",mx)
            # Integer does not support NA, therefore, NA needs to be filled
            if not np.isfinite(df[col]).all(): 
                NAlist.append(col)
                df[col].fillna(mn-1,inplace=True)  
                   
            # test if column can be converted to an integer
            asint = df[col].fillna(0).astype(np.int64)
            result = (df[col] - asint)
            result = result.sum()
            if result > -0.01 and result < 0.01:
                IsInt = True            
            # Make Integer/unsigned Integer datatypes
            if IsInt:
                if mn >= 0:
                    if mx < 255:
                        df[col] = df[col].astype(np.uint8)
                    elif mx < 65535:
                        df[col] = df[col].astype(np.uint16)
                    elif mx < 4294967295:
                        df[col] = df[col].astype(np.uint32)
                    else:
                        df[col] = df[col].astype(np.uint64)
                else:
                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:
                        df[col] = df[col].astype(np.int8)
                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:
                        df[col] = df[col].astype(np.int16)
                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:
                        df[col] = df[col].astype(np.int32)
                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:
                        df[col] = df[col].astype(np.int64)    
            # Make float datatypes 32 bit
            else:
                df[col] = df[col].astype(np.float32)
            
            # Print new column type
            print("dtype after: ",df[col].dtype)
            print("******************************")
    # Print final result
    print("___MEMORY USAGE AFTER COMPLETION:___")
    mem_usg = df.memory_usage().sum() / 1024**2 
    print("Memory usage is: ",mem_usg," MB")
    print("This is ",100*mem_usg/start_mem_usg,"% of the initial size")
    return df, NAlist

! gdown 1kh-WFXG3xiCm7R3Wnh3xeo78MjZOoeqt

! gdown 1bQsVod5JTywfx_s7HvY3h1X9UWAwtnZd

! gdown 1ppQSr_2XNn-jw0xy70AENQuYIwGrNKM8

train=pd.read_csv('IEEE_train.csv')
test=pd.read_csv('IEEE_test.csv')

#train,_=reduce_memory_usage(train)
#test,_=reduce_memory_usage(test)

def AUC(y_true, y_score):
  return roc_auc_score(y_true, y_score)

def seed_everything(seed=0):
    random.seed(seed)
    np.random.seed(seed)

X=train.drop('isFraud', axis=1)
y=train['isFraud']
X_test=test

del train, test
gc.collect()

SEED=2022
seed_everything(SEED)

params = {
    "n_estimators": 5000,
    "boosting_type": "gbdt",
    "num_leaves": 100, #2^("max_depth")
    "max_depth":-1,
    "learning_rate": 0.1,
    "reg_lambda": 50,
    "colsample_bytree":0.1,
    "metric":"auc",
    "bagging_fraction":1,
    "bagging_freq":1,
    "min_child_samples": 600,
    "max_bin": 300
        }

NFOLDS=5
seed_range=3
gkf=GroupKFold(n_splits=NFOLDS)
groups=np.ceil(X['transaction_day']/7)

preds_seed=np.zeros((X_test.shape[0],seed_range))
val_preds_seed=np.zeros((X.shape[0],seed_range))

for i, s in enumerate(range(SEED, SEED+seed_range)):
  print('SEED:', s)
  preds = np.zeros((X_test.shape[0], NFOLDS))
  val_preds=np.zeros(X.shape[0])
  seed_everything(s)
  params['seed'] = s
  
  for j, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):
    fold = j + 1
    print('Fold:',fold,'\n')

    kf_X_train=X.iloc[train_idx]
    kf_y_train=y.iloc[train_idx]
    
    kf_X_test=X.iloc[test_idx]
    kf_y_test=y.iloc[test_idx]

    classifier=LGBMClassifier(**params)
    classifier.fit(kf_X_train,kf_y_train, eval_set=[(kf_X_train,kf_y_train), (kf_X_test,kf_y_test)],
              eval_names=['train', 'test'], eval_metric='auc',
                early_stopping_rounds=500,verbose=100)
                
    val_preds[test_idx]+= classifier.predict_proba(kf_X_test)[:,1]
    preds[:, j] = classifier.predict_proba(X_test)[:,1]
      
  preds=gmean(preds, axis=1)
  preds_seed[:,i]=preds
  val_preds_seed[:,i]=val_preds

preds_proba=gmean(preds_seed, axis=1)
val_preds_seed_proba=gmean(val_preds_seed, axis=1)

np.save('pred_lgb.npy', preds_proba)
np.save('val_pred_lgb.npy', val_preds_seed_proba)

"""**Local CV**"""

AUC(y,val_preds_seed_proba)

#def to_labels(pos_probs, threshold):
#	return (pos_probs >= threshold).astype('int')
 
#thresholds = np.arange(0, 1, 0.001)
#scores = [AUC(y, to_labels(val_preds_seed_proba, t)) for t in thresholds]
#ix = np.argmax(scores)
#print('Threshold=%.3f, AUC=%.5f' % (thresholds[ix], scores[ix]))

#preds=np.where(preds_proba<thresholds[ix], 0, 1)

"""**Submission**"""

submission=pd.read_csv('sample_submission.csv')

#submission['isFraud']=preds

submission['isFraud']=preds_proba

submission.to_csv('submission_lgb.csv', index=False)

from google.colab import files

files.download('submission_lgb.csv')